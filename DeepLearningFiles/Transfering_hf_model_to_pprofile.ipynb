{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOFi4gGmpd3FjinZULr5h8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avikumart/LLM-GenAI-Transformers-Notebooks/blob/main/DeepLearningFiles/Transfering_hf_model_to_pprofile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token \"your_hf_token\""
      ],
      "metadata": {
        "id": "Ov6LuGq6xPgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHiangMOwBvB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import os\n",
        "\n",
        "# 1. Define the local directory where your model was saved (e.g., from trainer.save_model)\n",
        "MODEL_DIR = \"meta-llama/Llama-3.2-1B\"\n",
        "\n",
        "# 2. Define the name for your new repository on the Hugging Face Hub\n",
        "# The format will be: <your_username>/<REPO_NAME>\n",
        "REPO_NAME = \"avikumart/llama_3.2_1b\"\n",
        "\n",
        "# --- Load the model and tokenizer from your local save folder ---\n",
        "# Load model (can be a specific class like LlamaForCausalLM or generic AutoModel)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_DIR)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
        "\n",
        "# 3. Push the model and tokenizer to the Hub\n",
        "# This creates a new repository under your namespace with the name specified.\n",
        "print(f\"Uploading model to Hugging Face Hub as: {REPO_NAME}\")\n",
        "\n",
        "# Push the model\n",
        "model.push_to_hub(REPO_NAME)\n",
        "\n",
        "# Push the tokenizer (adds necessary vocabulary/config files to the same repo)\n",
        "tokenizer.push_to_hub(REPO_NAME)\n",
        "\n",
        "print(f\"Upload complete! View your model at: https://huggingface.co/avikumart/{REPO_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate"
      ],
      "metadata": {
        "id": "Ntz1lLXm1SjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate.__version__"
      ],
      "metadata": {
        "id": "IwEqWJyM1U07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VmxEYmy11XEB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}