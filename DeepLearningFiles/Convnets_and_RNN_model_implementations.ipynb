{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJedO/qnKXf8WyIUwnTury",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avikumart/LLM-GenAI-Transformers-Notebooks/blob/main/DeepLearningFiles/Convnets_and_RNN_model_implementations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3rcTC76wxepo"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The main code for the recurrent and convolutional networks assignment.\n",
        "See README.md for details.\n",
        "\"\"\"\n",
        "from typing import Tuple, List, Dict\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "\n",
        "def create_toy_rnn(input_shape: tuple, n_outputs: int) \\\n",
        "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
        "    \"\"\"Creates a recurrent neural network for a toy problem.\n",
        "\n",
        "    The network will take as input a sequence of number pairs, (x_{t}, y_{t}),\n",
        "    where t is the time step. It must learn to produce x_{t-3} - y{t} as the\n",
        "    output of time step t.\n",
        "\n",
        "    This method does not call Model.fit, but the dictionary it returns alongside\n",
        "    the model will be passed as extra arguments whenever Model.fit is called.\n",
        "    This can be used to, for example, set the batch size or use early stopping.\n",
        "\n",
        "    :param input_shape: The shape of the inputs to the model.\n",
        "    :param n_outputs: The number of outputs from the model.\n",
        "    :return: A tuple of (neural network, Model.fit keyword arguments)\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    model = tensorflow.keras.models.Sequential()\n",
        "    model.add(tensorflow.keras.layers.SimpleRNN(128, dropout=0.10, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(tensorflow.keras.layers.SimpleRNN(128, dropout=0.10, return_sequences=True))\n",
        "    model.add(tensorflow.keras.layers.SimpleRNN(128, dropout=0.10, return_sequences=True))\n",
        "    model.add(tensorflow.keras.layers.Dropout(0.2))\n",
        "    model.add(tensorflow.keras.layers.Dense(n_outputs, activation='linear'))\n",
        "    model.compile(loss=tensorflow.keras.losses.MeanSquaredError, optimizer='adam')\n",
        "    return model, dict(batch_size=5)\n",
        "\n",
        "def create_mnist_cnn(input_shape: tuple, n_outputs: int) \\\n",
        "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
        "    \"\"\"Creates a convolutional neural network for digit classification.\n",
        "\n",
        "    The network will take as input a 28x28 grayscale image, and produce as\n",
        "    output one of the digits 0 through 9. The network will be trained and tested\n",
        "    on a fraction of the MNIST data: http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "    This method does not call Model.fit, but the dictionary it returns alongside\n",
        "    the model will be passed as extra arguments whenever Model.fit is called.\n",
        "    This can be used to, for example, set the batch size or use early stopping.\n",
        "\n",
        "    :param input_shape: The shape of the inputs to the model.\n",
        "    :param n_outputs: The number of outputs from the model.\n",
        "    :return: A tuple of (neural network, Model.fit keyword arguments)\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    model = tensorflow.keras.models.Sequential()\n",
        "    model.add(tensorflow.keras.layers.Conv2D(128, kernel_size=(2, 2), activation='relu', padding=\"same\", input_shape=input_shape))\n",
        "    model.add(tensorflow.keras.layers.Conv2D(128, (2, 2), padding=\"same\", activation='relu'))\n",
        "    model.add(tensorflow.keras.layers.Conv2D(128, (2, 2), padding=\"same\", activation='relu'))\n",
        "    model.add(tensorflow.keras.layers.Flatten())\n",
        "    model.add(tensorflow.keras.layers.Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(loss=tensorflow.keras.losses.categorical_crossentropy, optimizer=tensorflow.keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "    return model, dict(batch_size=5)\n",
        "\n",
        "def create_youtube_comment_rnn(vocabulary: List[str], n_outputs: int) \\\n",
        "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
        "    \"\"\"Creates a recurrent neural network for spam classification.\n",
        "\n",
        "    This network will take as input a YouTube comment, and produce as output\n",
        "    either 1, for spam, or 0, for ham (non-spam). The network will be trained\n",
        "    and tested on data from:\n",
        "    https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection\n",
        "\n",
        "    Each comment is represented as a series of tokens, with each token\n",
        "    represented by a number, which is its index in the vocabulary. Note that\n",
        "    comments may be of variable length, so in the input matrix, comments with\n",
        "    fewer tokens than the matrix width will be right-padded with zeros.\n",
        "\n",
        "    This method does not call Model.fit, but the dictionary it returns alongside\n",
        "    the model will be passed as extra arguments whenever Model.fit is called.\n",
        "    This can be used to, for example, set the batch size or use early stopping.\n",
        "\n",
        "    :param vocabulary: The vocabulary defining token indexes.\n",
        "    :param n_outputs: The number of outputs from the model.\n",
        "    :return: A tuple of (neural network, Model.fit keyword arguments)\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    model = tensorflow.keras.models.Sequential()\n",
        "    model.add(tensorflow.keras.layers.Input(shape=(5,)))\n",
        "    model.add(tensorflow.keras.layers.Embedding(len(vocabulary), 128, mask_zero=True))\n",
        "    model.add(tensorflow.keras.layers.LSTM(64, dropout=0.2, return_sequences=True))\n",
        "    model.add(tensorflow.keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(tensorflow.keras.layers.Dense(n_outputs, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model, dict(batch_size=5)\n",
        "\n",
        "def create_youtube_comment_cnn(vocabulary: List[str], n_outputs: int) \\\n",
        "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
        "    \"\"\"moCreates a convolutional neural network for spam classification.\n",
        "\n",
        "    This network will take as input a YouTube comment, and produce as output\n",
        "    either 1, for spam, or 0, for ham (non-spam). The network will be trained\n",
        "    and tested on data from:\n",
        "    https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection\n",
        "\n",
        "    Each comment is represented as a series of tokens, with each token\n",
        "    represented by a number, which is its index in the vocabulary. Note that\n",
        "    comments may be of variable length, so in the input matrix, comments with\n",
        "    fewer tokens than the matrix width will be right-padded with zeros.\n",
        "\n",
        "    This method does not call Model.fit, but the dictionary it returns alongside\n",
        "    the model will be passed as extra arguments whenever Model.fit is called.\n",
        "    This can be used to, for example, set the batch size or use early stopping.\n",
        "\n",
        "    :param vocabulary: The vocabulary defining token indexes.\n",
        "    :param n_outputs: The number of outputs from the model.\n",
        "    :return: A tuple of (neural network, Model.fit keyword arguments)\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    model = tensorflow.keras.models.Sequential()\n",
        "    model.add(tensorflow.keras.layers.Embedding(len(vocabulary), 15))\n",
        "    model.add(tensorflow.keras.layers.Conv1D(128, 5, activation='relu'))\n",
        "    model.add(tensorflow.keras.layers.GlobalMaxPooling1D())\n",
        "    model.add(tensorflow.keras.layers.Dense(10, activation='relu'))\n",
        "    model.add(tensorflow.keras.layers.Dense(n_outputs, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model, dict(batch_size=5)"
      ]
    }
  ]
}