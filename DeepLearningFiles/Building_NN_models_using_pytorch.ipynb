{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMu2bLaDIk0Ee58qcW2N480",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avikumart/LLM-GenAI-Transformers-Notebooks/blob/main/DeepLearningFiles/Building_NN_models_using_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Basics / Tensor operations"
      ],
      "metadata": {
        "id": "ly7WMe_oU_iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. [source:](https://www.kaggle.com/code/kanncaa1/pytorch-tutorial-for-deep-learning-lovers)\n",
        "\n",
        "2. [G4G docs](https://www.geeksforgeeks.org/start-learning-pytorch-for-beginners/)"
      ],
      "metadata": {
        "id": "jntQhfVhq8Jb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t1M3NRxyN9sz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([[23,34,56,2],\n",
        "                [12,41,52,5]])\n",
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h0_bRnjVLfe",
        "outputId": "0d7a4d6b-3c78-4d4c-c676-e5b898b49e3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23, 34, 56,  2],\n",
              "       [12, 41, 52,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor(arr)\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JFTd2nsVRI9",
        "outputId": "e1c79aa1-1594-4b9a-d536-1682d7e686d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[23, 34, 56,  2],\n",
              "        [12, 41, 52,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdLRPUqZVWg-",
        "outputId": "f7685a20-88f8-4860-b25c-6a5933cef913"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some random pytorch tensors\n",
        "torch.rand(4,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlpJKl3UVZ0e",
        "outputId": "61ab6dd4-4c70-4ac4-8f5e-054436b32300"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4359, 0.1772, 0.1798],\n",
              "        [0.3742, 0.1567, 0.1454],\n",
              "        [0.1976, 0.6318, 0.3414],\n",
              "        [0.6540, 0.9301, 0.4885]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(4,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMCHWx1kV-fJ",
        "outputId": "b15bdb45-0865-4fb1-b7ad-64e5adf840fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ten = torch.from_numpy(arr)\n",
        "ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqfznZaxWBnI",
        "outputId": "905a0611-b660-4893-9936-cbb70b7fd1d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[23, 34, 56,  2],\n",
              "        [12, 41, 52,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr1 = ten.numpy()\n",
        "arr1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSdDI3RbWNT3",
        "outputId": "e60fe0b4-151f-4fe7-ffb9-ce5d33f97b6c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23, 34, 56,  2],\n",
              "       [12, 41, 52,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(3,4)\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8Ei9vi3WREl",
        "outputId": "1026552a-8afd-4f5e-9c55-c6e2819ef2ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# addition\n",
        "torch.add(tensor,tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB2FWgfNWiZW",
        "outputId": "0ba9f95d-f8d6-4244-d5b6-2ca734c2ce78"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sub(tensor,tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA0Z2h6TXWsS",
        "outputId": "8824bcb5-4960-46c6-93cf-09f82cbb526f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mul(tensor,tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlaQpaFqXfD6",
        "outputId": "7c36719b-1904-4e38-9ef4-f126e19592e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqoH-ZGtXoUd",
        "outputId": "abdc0a49-1522-488a-cc44-25a7cbf4add0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import variable form pytorch library\n",
        "from torch.autograd import Variable\n",
        "\n",
        "var = Variable(torch.rand(3,4),requires_grad=True)\n",
        "var"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g65Zf3I4Ygb_",
        "outputId": "7d19595a-1400-424e-e860-9c5fa259ff12"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4910, 0.1859, 0.4139, 0.7076],\n",
              "        [0.6373, 0.1643, 0.2796, 0.2785],\n",
              "        [0.5831, 0.9059, 0.3838, 0.9612]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backward propagation of the equation y = x^2\n",
        "array = [2,4]\n",
        "tensor = torch.Tensor(array)\n",
        "\n",
        "x = Variable(tensor,requires_grad=True)\n",
        "y = x**2\n",
        "\n",
        "print(\"y  :\",y)\n",
        "\n",
        "o = (1/2)*sum(y)\n",
        "print(\"o  :\",o)\n",
        "\n",
        "o.backward()\n",
        "print(\"x.grad  :\",x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl_l6k2eYwgg",
        "outputId": "13adc630-8150-4e04-d4e1-e8f9c00b2599"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y  : tensor([ 4., 16.], grad_fn=<PowBackward0>)\n",
            "o  : tensor(10., grad_fn=<MulBackward0>)\n",
            "x.grad  : tensor([2., 4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression model using pytorch"
      ],
      "metadata": {
        "id": "lDODjMuSdCjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate dummay x and y data\n",
        "x = np.random.rand(100,1)\n",
        "y = 2 + 3*x + np.random.rand(100,1)\n",
        "\n",
        "# convert to the tensor\n",
        "ten_x = torch.Tensor(x)\n",
        "ten_y = torch.Tensor(y)\n",
        "\n",
        "# make the data optimizable\n",
        "ten_x = Variable(ten_x,requires_grad=True)\n",
        "ten_y = Variable(ten_y)"
      ],
      "metadata": {
        "id": "XjZPX7K_cIvd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the chart of the x and y\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(ten_x.data.numpy(),ten_y.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "L3QiVtdgfxo7",
        "outputId": "5dafc5e0-5b2a-4bb9-9205-740ef905cb1a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7be85e9fcdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the linear regression model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import SGD\n",
        "\n",
        "# create the linear regression class\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(LinearRegression,self).__init__()\n",
        "        self.linear = nn.Linear(input_size,output_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.linear(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "FlEPtFpsgha-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "model = LinearRegression(1,1)\n",
        "\n",
        "# define the loss\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "l-Ho7W8liin4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "loss_list = []\n",
        "epochs = 10002\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  results = model(ten_x)\n",
        "  loss = loss_fn(results,ten_y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  loss_list.append(loss.data)\n",
        "  if epoch % 50 == 0:\n",
        "    print(f\"epoch: {epoch}, loss: {loss.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjloF7aWixbN",
        "outputId": "50b811a8-aabf-4c27-f21b-7a71d3167ef1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss: 23.446332931518555\n",
            "epoch: 50, loss: 1.7752615213394165\n",
            "epoch: 100, loss: 0.20679788291454315\n",
            "epoch: 150, loss: 0.09237940609455109\n",
            "epoch: 200, loss: 0.08323995769023895\n",
            "epoch: 250, loss: 0.08181694895029068\n",
            "epoch: 300, loss: 0.08104223012924194\n",
            "epoch: 350, loss: 0.08039392530918121\n",
            "epoch: 400, loss: 0.07982474565505981\n",
            "epoch: 450, loss: 0.07932315766811371\n",
            "epoch: 500, loss: 0.07888093590736389\n",
            "epoch: 550, loss: 0.07849103212356567\n",
            "epoch: 600, loss: 0.07814721763134003\n",
            "epoch: 650, loss: 0.07784412056207657\n",
            "epoch: 700, loss: 0.07757687568664551\n",
            "epoch: 750, loss: 0.07734129577875137\n",
            "epoch: 800, loss: 0.07713355123996735\n",
            "epoch: 850, loss: 0.07695035636425018\n",
            "epoch: 900, loss: 0.07678885757923126\n",
            "epoch: 950, loss: 0.07664647698402405\n",
            "epoch: 1000, loss: 0.07652091979980469\n",
            "epoch: 1050, loss: 0.07641022652387619\n",
            "epoch: 1100, loss: 0.07631263881921768\n",
            "epoch: 1150, loss: 0.0762265995144844\n",
            "epoch: 1200, loss: 0.07615074515342712\n",
            "epoch: 1250, loss: 0.07608383893966675\n",
            "epoch: 1300, loss: 0.07602488249540329\n",
            "epoch: 1350, loss: 0.07597286999225616\n",
            "epoch: 1400, loss: 0.07592702656984329\n",
            "epoch: 1450, loss: 0.07588659971952438\n",
            "epoch: 1500, loss: 0.07585097849369049\n",
            "epoch: 1550, loss: 0.07581953704357147\n",
            "epoch: 1600, loss: 0.07579182833433151\n",
            "epoch: 1650, loss: 0.0757674053311348\n",
            "epoch: 1700, loss: 0.07574586570262909\n",
            "epoch: 1750, loss: 0.07572687417268753\n",
            "epoch: 1800, loss: 0.07571014761924744\n",
            "epoch: 1850, loss: 0.07569538801908493\n",
            "epoch: 1900, loss: 0.0756823793053627\n",
            "epoch: 1950, loss: 0.07567089051008224\n",
            "epoch: 2000, loss: 0.07566076517105103\n",
            "epoch: 2050, loss: 0.07565184682607651\n",
            "epoch: 2100, loss: 0.07564398646354675\n",
            "epoch: 2150, loss: 0.07563705742359161\n",
            "epoch: 2200, loss: 0.07563092559576035\n",
            "epoch: 2250, loss: 0.07562554627656937\n",
            "epoch: 2300, loss: 0.07562080025672913\n",
            "epoch: 2350, loss: 0.07561661303043365\n",
            "epoch: 2400, loss: 0.07561289519071579\n",
            "epoch: 2450, loss: 0.07560966163873672\n",
            "epoch: 2500, loss: 0.07560678571462631\n",
            "epoch: 2550, loss: 0.07560424506664276\n",
            "epoch: 2600, loss: 0.07560201734304428\n",
            "epoch: 2650, loss: 0.0756000503897667\n",
            "epoch: 2700, loss: 0.07559830695390701\n",
            "epoch: 2750, loss: 0.07559676468372345\n",
            "epoch: 2800, loss: 0.075595423579216\n",
            "epoch: 2850, loss: 0.07559424638748169\n",
            "epoch: 2900, loss: 0.07559320330619812\n",
            "epoch: 2950, loss: 0.0755922868847847\n",
            "epoch: 3000, loss: 0.07559146732091904\n",
            "epoch: 3050, loss: 0.07559073716402054\n",
            "epoch: 3100, loss: 0.0755901038646698\n",
            "epoch: 3150, loss: 0.07558953762054443\n",
            "epoch: 3200, loss: 0.07558903843164444\n",
            "epoch: 3250, loss: 0.07558861374855042\n",
            "epoch: 3300, loss: 0.07558823376893997\n",
            "epoch: 3350, loss: 0.07558789104223251\n",
            "epoch: 3400, loss: 0.07558760046958923\n",
            "epoch: 3450, loss: 0.07558734714984894\n",
            "epoch: 3500, loss: 0.07558711618185043\n",
            "epoch: 3550, loss: 0.07558690756559372\n",
            "epoch: 3600, loss: 0.0755867138504982\n",
            "epoch: 3650, loss: 0.07558654993772507\n",
            "epoch: 3700, loss: 0.07558642327785492\n",
            "epoch: 3750, loss: 0.07558628916740417\n",
            "epoch: 3800, loss: 0.07558619230985641\n",
            "epoch: 3850, loss: 0.07558610290288925\n",
            "epoch: 3900, loss: 0.07558602094650269\n",
            "epoch: 3950, loss: 0.07558593153953552\n",
            "epoch: 4000, loss: 0.07558587193489075\n",
            "epoch: 4050, loss: 0.07558581233024597\n",
            "epoch: 4100, loss: 0.0755857527256012\n",
            "epoch: 4150, loss: 0.07558570057153702\n",
            "epoch: 4200, loss: 0.07558567076921463\n",
            "epoch: 4250, loss: 0.07558564841747284\n",
            "epoch: 4300, loss: 0.07558561116456985\n",
            "epoch: 4350, loss: 0.07558558136224747\n",
            "epoch: 4400, loss: 0.07558555901050568\n",
            "epoch: 4450, loss: 0.07558552920818329\n",
            "epoch: 4500, loss: 0.07558552920818329\n",
            "epoch: 4550, loss: 0.0755855068564415\n",
            "epoch: 4600, loss: 0.07558548450469971\n",
            "epoch: 4650, loss: 0.07558547705411911\n",
            "epoch: 4700, loss: 0.07558546215295792\n",
            "epoch: 4750, loss: 0.07558545470237732\n",
            "epoch: 4800, loss: 0.07558545470237732\n",
            "epoch: 4850, loss: 0.07558545470237732\n",
            "epoch: 4900, loss: 0.07558543980121613\n",
            "epoch: 4950, loss: 0.07558543235063553\n",
            "epoch: 5000, loss: 0.07558542490005493\n",
            "epoch: 5050, loss: 0.07558540254831314\n",
            "epoch: 5100, loss: 0.07558540999889374\n",
            "epoch: 5150, loss: 0.07558540254831314\n",
            "epoch: 5200, loss: 0.07558540254831314\n",
            "epoch: 5250, loss: 0.07558539509773254\n",
            "epoch: 5300, loss: 0.07558539509773254\n",
            "epoch: 5350, loss: 0.07558540254831314\n",
            "epoch: 5400, loss: 0.07558538019657135\n",
            "epoch: 5450, loss: 0.07558538764715195\n",
            "epoch: 5500, loss: 0.07558539509773254\n",
            "epoch: 5550, loss: 0.07558539509773254\n",
            "epoch: 5600, loss: 0.07558538764715195\n",
            "epoch: 5650, loss: 0.07558538764715195\n",
            "epoch: 5700, loss: 0.07558537274599075\n",
            "epoch: 5750, loss: 0.07558538019657135\n",
            "epoch: 5800, loss: 0.07558538019657135\n",
            "epoch: 5850, loss: 0.07558537274599075\n",
            "epoch: 5900, loss: 0.07558538764715195\n",
            "epoch: 5950, loss: 0.07558537274599075\n",
            "epoch: 6000, loss: 0.07558537274599075\n",
            "epoch: 6050, loss: 0.07558538019657135\n",
            "epoch: 6100, loss: 0.07558538764715195\n",
            "epoch: 6150, loss: 0.07558538764715195\n",
            "epoch: 6200, loss: 0.07558538019657135\n",
            "epoch: 6250, loss: 0.07558538019657135\n",
            "epoch: 6300, loss: 0.07558538764715195\n",
            "epoch: 6350, loss: 0.07558537274599075\n",
            "epoch: 6400, loss: 0.07558536529541016\n",
            "epoch: 6450, loss: 0.07558536529541016\n",
            "epoch: 6500, loss: 0.07558539509773254\n",
            "epoch: 6550, loss: 0.07558539509773254\n",
            "epoch: 6600, loss: 0.07558539509773254\n",
            "epoch: 6650, loss: 0.07558539509773254\n",
            "epoch: 6700, loss: 0.07558539509773254\n",
            "epoch: 6750, loss: 0.07558539509773254\n",
            "epoch: 6800, loss: 0.07558539509773254\n",
            "epoch: 6850, loss: 0.07558539509773254\n",
            "epoch: 6900, loss: 0.07558539509773254\n",
            "epoch: 6950, loss: 0.07558539509773254\n",
            "epoch: 7000, loss: 0.07558539509773254\n",
            "epoch: 7050, loss: 0.07558539509773254\n",
            "epoch: 7100, loss: 0.07558539509773254\n",
            "epoch: 7150, loss: 0.07558539509773254\n",
            "epoch: 7200, loss: 0.07558539509773254\n",
            "epoch: 7250, loss: 0.07558539509773254\n",
            "epoch: 7300, loss: 0.07558539509773254\n",
            "epoch: 7350, loss: 0.07558539509773254\n",
            "epoch: 7400, loss: 0.07558539509773254\n",
            "epoch: 7450, loss: 0.07558539509773254\n",
            "epoch: 7500, loss: 0.07558539509773254\n",
            "epoch: 7550, loss: 0.07558539509773254\n",
            "epoch: 7600, loss: 0.07558539509773254\n",
            "epoch: 7650, loss: 0.07558539509773254\n",
            "epoch: 7700, loss: 0.07558539509773254\n",
            "epoch: 7750, loss: 0.07558539509773254\n",
            "epoch: 7800, loss: 0.07558539509773254\n",
            "epoch: 7850, loss: 0.07558539509773254\n",
            "epoch: 7900, loss: 0.07558539509773254\n",
            "epoch: 7950, loss: 0.07558539509773254\n",
            "epoch: 8000, loss: 0.07558539509773254\n",
            "epoch: 8050, loss: 0.07558539509773254\n",
            "epoch: 8100, loss: 0.07558539509773254\n",
            "epoch: 8150, loss: 0.07558539509773254\n",
            "epoch: 8200, loss: 0.07558539509773254\n",
            "epoch: 8250, loss: 0.07558539509773254\n",
            "epoch: 8300, loss: 0.07558539509773254\n",
            "epoch: 8350, loss: 0.07558539509773254\n",
            "epoch: 8400, loss: 0.07558539509773254\n",
            "epoch: 8450, loss: 0.07558539509773254\n",
            "epoch: 8500, loss: 0.07558539509773254\n",
            "epoch: 8550, loss: 0.07558539509773254\n",
            "epoch: 8600, loss: 0.07558539509773254\n",
            "epoch: 8650, loss: 0.07558539509773254\n",
            "epoch: 8700, loss: 0.07558539509773254\n",
            "epoch: 8750, loss: 0.07558539509773254\n",
            "epoch: 8800, loss: 0.07558539509773254\n",
            "epoch: 8850, loss: 0.07558539509773254\n",
            "epoch: 8900, loss: 0.07558539509773254\n",
            "epoch: 8950, loss: 0.07558539509773254\n",
            "epoch: 9000, loss: 0.07558539509773254\n",
            "epoch: 9050, loss: 0.07558539509773254\n",
            "epoch: 9100, loss: 0.07558539509773254\n",
            "epoch: 9150, loss: 0.07558539509773254\n",
            "epoch: 9200, loss: 0.07558539509773254\n",
            "epoch: 9250, loss: 0.07558539509773254\n",
            "epoch: 9300, loss: 0.07558539509773254\n",
            "epoch: 9350, loss: 0.07558539509773254\n",
            "epoch: 9400, loss: 0.07558539509773254\n",
            "epoch: 9450, loss: 0.07558539509773254\n",
            "epoch: 9500, loss: 0.07558539509773254\n",
            "epoch: 9550, loss: 0.07558539509773254\n",
            "epoch: 9600, loss: 0.07558539509773254\n",
            "epoch: 9650, loss: 0.07558539509773254\n",
            "epoch: 9700, loss: 0.07558539509773254\n",
            "epoch: 9750, loss: 0.07558539509773254\n",
            "epoch: 9800, loss: 0.07558539509773254\n",
            "epoch: 9850, loss: 0.07558539509773254\n",
            "epoch: 9900, loss: 0.07558539509773254\n",
            "epoch: 9950, loss: 0.07558539509773254\n",
            "epoch: 10000, loss: 0.07558539509773254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression using pytorch"
      ],
      "metadata": {
        "id": "G8xSOT7e7uPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optimize\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# import load iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# train and test split the dataset\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# convert the dataet into pytorch tensors\n",
        "train_X = torch.Tensor(X_train)\n",
        "train_y = torch.Tensor(y_train)\n",
        "\n",
        "test_X = torch.Tensor(X_test)\n",
        "test_y = torch.Tensor(y_test)"
      ],
      "metadata": {
        "id": "BIO0_BC_6hOR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "class LogReg(nn.Module):\n",
        "  def __init__(self, input_dim,hidden_size, output_dim):\n",
        "    super(LogReg,self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim,hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size,output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "lQu3maMM2wwr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = train_X.shape[1]\n",
        "hidden_size = 15\n",
        "output_dim = len(iris.target_names)\n",
        "\n",
        "# create the model\n",
        "model = LogReg(input_dim,hidden_size,output_dim)\n",
        "\n",
        "# define the loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = optimize.Adam(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "hvBDDAYw3N1o"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "num_epochs = 1000\n",
        "for e in range(num_epochs):\n",
        "  # start the optimizer\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(train_X)\n",
        "  loss = loss_fn(outputs,train_y.long()) # does the softmax and calculates the loss function\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if e%10 == 0:\n",
        "    print(f\"epoch: {e}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lue4HIG33hi5",
        "outputId": "af8c3ecf-914d-407c-acb0-7c8ef07cb28b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss: 1.024781346321106\n",
            "epoch: 10, loss: 0.6306218504905701\n",
            "epoch: 20, loss: 0.41752663254737854\n",
            "epoch: 30, loss: 0.3258104920387268\n",
            "epoch: 40, loss: 0.2584036886692047\n",
            "epoch: 50, loss: 0.2011742889881134\n",
            "epoch: 60, loss: 0.15425674617290497\n",
            "epoch: 70, loss: 0.1196746677160263\n",
            "epoch: 80, loss: 0.09812083840370178\n",
            "epoch: 90, loss: 0.08410200476646423\n",
            "epoch: 100, loss: 0.07501719146966934\n",
            "epoch: 110, loss: 0.0689409002661705\n",
            "epoch: 120, loss: 0.06453175842761993\n",
            "epoch: 130, loss: 0.0611845925450325\n",
            "epoch: 140, loss: 0.0585487000644207\n",
            "epoch: 150, loss: 0.05640735104680061\n",
            "epoch: 160, loss: 0.05462953820824623\n",
            "epoch: 170, loss: 0.053128328174352646\n",
            "epoch: 180, loss: 0.05185503512620926\n",
            "epoch: 190, loss: 0.05077585205435753\n",
            "epoch: 200, loss: 0.049834802746772766\n",
            "epoch: 210, loss: 0.049020152539014816\n",
            "epoch: 220, loss: 0.04830692335963249\n",
            "epoch: 230, loss: 0.04767972230911255\n",
            "epoch: 240, loss: 0.0471285842359066\n",
            "epoch: 250, loss: 0.046640824526548386\n",
            "epoch: 260, loss: 0.046209465712308884\n",
            "epoch: 270, loss: 0.04582609981298447\n",
            "epoch: 280, loss: 0.04548182711005211\n",
            "epoch: 290, loss: 0.04516984149813652\n",
            "epoch: 300, loss: 0.044891152530908585\n",
            "epoch: 310, loss: 0.0446428582072258\n",
            "epoch: 320, loss: 0.044405724853277206\n",
            "epoch: 330, loss: 0.044195640832185745\n",
            "epoch: 340, loss: 0.044004444032907486\n",
            "epoch: 350, loss: 0.043836358934640884\n",
            "epoch: 360, loss: 0.043668750673532486\n",
            "epoch: 370, loss: 0.04352537915110588\n",
            "epoch: 380, loss: 0.04338807612657547\n",
            "epoch: 390, loss: 0.04326767846941948\n",
            "epoch: 400, loss: 0.04315369576215744\n",
            "epoch: 410, loss: 0.04304797947406769\n",
            "epoch: 420, loss: 0.04295160621404648\n",
            "epoch: 430, loss: 0.042867064476013184\n",
            "epoch: 440, loss: 0.042782314121723175\n",
            "epoch: 450, loss: 0.042705316096544266\n",
            "epoch: 460, loss: 0.04264111816883087\n",
            "epoch: 470, loss: 0.042571019381284714\n",
            "epoch: 480, loss: 0.042510733008384705\n",
            "epoch: 490, loss: 0.04245226830244064\n",
            "epoch: 500, loss: 0.042398132383823395\n",
            "epoch: 510, loss: 0.042350899428129196\n",
            "epoch: 520, loss: 0.04230496659874916\n",
            "epoch: 530, loss: 0.042259346693754196\n",
            "epoch: 540, loss: 0.04221537336707115\n",
            "epoch: 550, loss: 0.04217693954706192\n",
            "epoch: 560, loss: 0.042139291763305664\n",
            "epoch: 570, loss: 0.04210296645760536\n",
            "epoch: 580, loss: 0.04207034036517143\n",
            "epoch: 590, loss: 0.04203619807958603\n",
            "epoch: 600, loss: 0.04200784116983414\n",
            "epoch: 610, loss: 0.04198072850704193\n",
            "epoch: 620, loss: 0.04195394366979599\n",
            "epoch: 630, loss: 0.04192691296339035\n",
            "epoch: 640, loss: 0.04190295189619064\n",
            "epoch: 650, loss: 0.04187760874629021\n",
            "epoch: 660, loss: 0.041855014860630035\n",
            "epoch: 670, loss: 0.04183311387896538\n",
            "epoch: 680, loss: 0.04181206598877907\n",
            "epoch: 690, loss: 0.04179314896464348\n",
            "epoch: 700, loss: 0.04177399352192879\n",
            "epoch: 710, loss: 0.04175476357340813\n",
            "epoch: 720, loss: 0.041736867278814316\n",
            "epoch: 730, loss: 0.041717778891325\n",
            "epoch: 740, loss: 0.04170035570859909\n",
            "epoch: 750, loss: 0.041683148592710495\n",
            "epoch: 760, loss: 0.041666559875011444\n",
            "epoch: 770, loss: 0.04164968430995941\n",
            "epoch: 780, loss: 0.0416346974670887\n",
            "epoch: 790, loss: 0.04161860793828964\n",
            "epoch: 800, loss: 0.04160374030470848\n",
            "epoch: 810, loss: 0.0415894016623497\n",
            "epoch: 820, loss: 0.04157615080475807\n",
            "epoch: 830, loss: 0.0415642149746418\n",
            "epoch: 840, loss: 0.041548751294612885\n",
            "epoch: 850, loss: 0.041533734649419785\n",
            "epoch: 860, loss: 0.04152165725827217\n",
            "epoch: 870, loss: 0.04150759428739548\n",
            "epoch: 880, loss: 0.041493501514196396\n",
            "epoch: 890, loss: 0.041482534259557724\n",
            "epoch: 900, loss: 0.041468050330877304\n",
            "epoch: 910, loss: 0.041454609483480453\n",
            "epoch: 920, loss: 0.041442327201366425\n",
            "epoch: 930, loss: 0.04142957925796509\n",
            "epoch: 940, loss: 0.04141698777675629\n",
            "epoch: 950, loss: 0.04140401631593704\n",
            "epoch: 960, loss: 0.04139292985200882\n",
            "epoch: 970, loss: 0.04138147458434105\n",
            "epoch: 980, loss: 0.04136756435036659\n",
            "epoch: 990, loss: 0.041355572640895844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of the model\n",
        "with torch.no_grad():\n",
        "  outputs = model(test_X)\n",
        "  _, predicts = torch.max(outputs,1)\n",
        "  acc = (predicts == test_y).sum().item() / test_y.size(0)\n",
        "  print(f\"accuracy: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo1URraPA3Wm",
        "outputId": "b337715a-fb23-447c-895a-f2dcdcc87444"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANN modeling using PyTorch on MNIST digit classification dataset"
      ],
      "metadata": {
        "id": "FgGbVmvhp0yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the mnist dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# load the dataset\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ3g9Es1p5P8",
        "outputId": "719b29c5-c46f-4cd4-ef14-acc61cff81f3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 9.91M/9.91M [00:00<00:00, 18.3MB/s]\n",
            "100%|| 28.9k/28.9k [00:00<00:00, 496kB/s]\n",
            "100%|| 1.65M/1.65M [00:00<00:00, 4.56MB/s]\n",
            "100%|| 4.54k/4.54k [00:00<00:00, 14.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size and epochs\n",
        "batch_size = 50\n",
        "epochs = 3\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "SIVWO_gtrBXe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model for the image classification\n",
        "class ANNModel(nn.Module):\n",
        "  def __init__(self, input, hidden, output):\n",
        "    super(ANNModel,self).__init__()\n",
        "    # ann model layers\n",
        "    self.fc1 = nn.Linear(input,hidden)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden,hidden)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.fc3 = nn.Linear(hidden,hidden)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.fc4 = nn.Linear(hidden,output)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # forward pass to the model\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.tanh(x)\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "_368i-aStjL9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the the input dim and output dim\n",
        "input = 28*28\n",
        "output = 10\n",
        "hidden = 100\n",
        "\n",
        "# model\n",
        "clf_model = ANNModel(input,hidden,output)\n",
        "\n",
        "# loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(clf_model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "Ia5znLeBw1LI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "count = 0\n",
        "loss_li = []\n",
        "iteration_li = []\n",
        "accuracy_li = []\n",
        "for epoch in range(epochs):\n",
        "  for idx, (images,labels) in enumerate(train_loader):\n",
        "\n",
        "    train_data = Variable(images.view(-1, 28 * 28))\n",
        "    labels = labels\n",
        "\n",
        "    # train the model and store the loss and acc in the list\n",
        "    optimizer.zero_grad()\n",
        "    outputs = clf_model(train_data)\n",
        "    loss = criterion(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    count += 1\n",
        "  if count % 5 == 0:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for (images,labels) in test_loader:\n",
        "      test_data = Variable(images.view(-1, 28*28))\n",
        "      outputs = clf_model(test_data)\n",
        "      prediction = torch.max(outputs.data,1)\n",
        "      total += labels.size(0)\n",
        "      correct += (prediction[1] == labels).sum()\n",
        "    accuracy1 = 100 * correct / total\n",
        "    loss_li.append(loss.data)\n",
        "    iteration_li.append(count)\n",
        "    accuracy_li.append(accuracy1)\n",
        "  if count % 10 ==0:\n",
        "      print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count,loss.item(),accuracy1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52njyVRBxN3h",
        "outputId": "612a6409-860e-4bfd-df84-f5fa5060d074"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1200, Loss: 0.010333175770938396, Accuracy: 97.51000213623047%\n",
            "Iteration: 2400, Loss: 0.016702312976121902, Accuracy: 97.2699966430664%\n",
            "Iteration: 3600, Loss: 0.0982096791267395, Accuracy: 97.48999786376953%\n"
          ]
        }
      ]
    }
  ]
}