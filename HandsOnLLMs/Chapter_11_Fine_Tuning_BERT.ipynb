{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avikumart/LLM-GenAI-Transformers-Notebooks/blob/main/HandsOnLLMs/Chapter_11_Fine_Tuning_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_a9QvUFVCUR"
      },
      "source": [
        "<h1>Chapter 11 - Fine-tuning Representation Models for Classification</h1>\n",
        "<i>Exploring the performance in classification of representation models.</i>\n",
        "\n",
        "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\"><img src=\"https://img.shields.io/badge/Buy%20the%20Book!-grey?logo=amazon\"></a>\n",
        "<a href=\"https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/\"><img src=\"https://img.shields.io/badge/O'Reilly-white.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMzQiIGhlaWdodD0iMjciIHZpZXdCb3g9IjAgMCAzNCAyNyIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTMiIGN5PSIxNCIgcj0iMTEiIHN0cm9rZT0iI0Q0MDEwMSIgc3Ryb2tlLXdpZHRoPSI0Ii8+CjxjaXJjbGUgY3g9IjMwLjUiIGN5PSIzLjUiIHI9IjMuNSIgZmlsbD0iI0Q0MDEwMSIvPgo8L3N2Zz4K\"></a>\n",
        "<a href=\"https://github.com/HandsOnLLM/Hands-On-Large-Language-Models\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter11/Chapter%2011%20-%20Fine-Tuning%20BERT.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is for Chapter 11 of the [Hands-On Large Language Models](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961) book by [Jay Alammar](https://www.linkedin.com/in/jalammar) and [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/).\n",
        "\n",
        "---\n",
        "\n",
        "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\">\n",
        "<img src=\"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png\" width=\"350\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT3Xq5w-4zd7"
      },
      "source": [
        "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
        "\n",
        "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ’¡ **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
        "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eTulu1M4zd7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"datasets>=2.18.0,<3\" transformers>=4.38.2 sentence-transformers>=2.5.1 setfit>=1.0.3 accelerate>=0.27.2 seqeval>=1.2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBeVnXxQWy7-"
      },
      "source": [
        "## **Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5phRS_z2U_3T"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Prepare data and splits\n",
        "tomatoes = load_dataset(\"rotten_tomatoes\")\n",
        "train_data, test_data = tomatoes[\"train\"], tomatoes[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xya5dfmVoR1R"
      },
      "source": [
        "## **Supervised Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODEmWQe8W_le"
      },
      "source": [
        "### HuggingFace Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-1UGAg7WAHk"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load Model and Tokenizer\n",
        "model_id = \"bert-base-cased\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r48vDo8fa33D"
      },
      "source": [
        "Tokenize our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ySNm-a3WCFI"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# Pad to the longest sequence in the batch\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "   \"\"\"Tokenize input data\"\"\"\n",
        "   return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "# Tokenize train/test data\n",
        "tokenized_train = train_data.map(preprocess_function, batched=True)\n",
        "tokenized_test = test_data.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ1NM1gjbMD7"
      },
      "source": [
        "Define metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y724gUYyWIvq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Calculate F1 score\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    load_f1 = evaluate.load(\"f1\")\n",
        "    f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "    return {\"f1\": f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAm-sAl9bOPC"
      },
      "source": [
        "Train model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dho6VcG9WK5u"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Training arguments for parameter tuning\n",
        "training_args = TrainingArguments(\n",
        "   \"model\",\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=1,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Trainer which executes the training process\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOzl0WnSbVnY"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkBUVlUYbUnn"
      },
      "source": [
        "Evaluate results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCI9uYDObWU8"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5gefwxOBllA"
      },
      "source": [
        "### Freeze Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0ZOuoe7Dj3c"
      },
      "outputs": [],
      "source": [
        "# Load Model and Tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI8vf_mnBniu"
      },
      "outputs": [],
      "source": [
        "# Print layer names\n",
        "for name, param in model.named_parameters():\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnpGOry_Bm36"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "\n",
        "     # Trainable classification head\n",
        "     if name.startswith(\"classifier\"):\n",
        "        param.requires_grad = True\n",
        "\n",
        "      # Freeze everything else\n",
        "     else:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf_wYzpMB4uX"
      },
      "outputs": [],
      "source": [
        "# We can check whether the model was correctly updated\n",
        "for name, param in model.named_parameters():\n",
        "     print(f\"Parameter: {name} ----- {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVi36FJSG4ue"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Trainer which executes the training process\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCPpixB1HCsI"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw729mLhIQL6"
      },
      "source": [
        "### Freeze blocks 1-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbsLR561Kje-"
      },
      "outputs": [],
      "source": [
        "# We can check whether the model was correctly updated\n",
        "for index, (name, param) in enumerate(model.named_parameters()):\n",
        "     print(f\"Parameter: {index}{name} ----- {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyleqOHICBjj"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model_id = \"bert-base-cased\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Encoder block 10 starts at index 165 and\n",
        "# we freeze everything before that block\n",
        "for index, (name, param) in enumerate(model.named_parameters()):\n",
        "    if index < 165:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Trainer which executes the training process\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "     print(f\"Parameter: {name} ----- {param.requires_grad}\")"
      ],
      "metadata": {
        "id": "P7DCGaBbBL83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJRMWsLdA913"
      },
      "source": [
        "### [BONUS] Freeze blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADvKJjNaFAot"
      },
      "outputs": [],
      "source": [
        "# scores = []\n",
        "# for index in range(12):\n",
        "#     # Re-load model\n",
        "#     model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "#     # Freeze encoder blocks 0-index\n",
        "#     for name, param in model.named_parameters():\n",
        "#         if \"layer\" in name:\n",
        "#             layer_nr = int(name.split(\"layer\")[1].split(\".\")[1])\n",
        "#             if layer_nr <= index:\n",
        "#                 param.requires_grad = False\n",
        "#         else:\n",
        "#             param.requires_grad = True\n",
        "\n",
        "#     # Train\n",
        "#     trainer = Trainer(\n",
        "#       model=model,\n",
        "#       args=training_args,\n",
        "#       train_dataset=tokenized_train,\n",
        "#       eval_dataset=tokenized_test,\n",
        "#       tokenizer=tokenizer,\n",
        "#       data_collator=data_collator,\n",
        "#       compute_metrics=compute_metrics,\n",
        "#     )\n",
        "#     trainer.train()\n",
        "\n",
        "#     # Evaluate\n",
        "#     score = trainer.evaluate()[\"eval_f1\"]\n",
        "#     scores.append(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWYlHFNdLQtk"
      },
      "outputs": [],
      "source": [
        "# scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf3PIvKhOBJ-"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Create Figure\n",
        "# plt.figure(figsize=(8,4))\n",
        "\n",
        "# # Prepare Data\n",
        "# x = [f\"0-{index}\" for index in range(12)]\n",
        "# x[0] = \"None\"\n",
        "# x[-1] = \"All\"\n",
        "# y = [\n",
        "#     0.8541862652869239,\n",
        "#     0.8525519848771267,\n",
        "#     0.8514664143803217,\n",
        "#     0.8506616257088847,\n",
        "#     0.8398104265402844,\n",
        "#     0.8391345249294448,\n",
        "#     0.8377358490566037,\n",
        "#     0.8433962264150944,\n",
        "#     0.8258801141769743,\n",
        "#     0.816247582205029,\n",
        "#     0.7917485265225934,\n",
        "#     0.7019400352733686\n",
        "# ][::-1]\n",
        "\n",
        "# # Stylize Figure\n",
        "# plt.grid(color='#ECEFF1')\n",
        "# plt.axvline(x=4, color=\"#EC407A\", linestyle=\"--\")\n",
        "# plt.title(\"Effect of Frozen Encoder Blocks on Training Performance\")\n",
        "# plt.ylabel(\"F1-score\")\n",
        "# plt.xlabel(\"Trainable encoder blocks\")\n",
        "\n",
        "# # Plot Data\n",
        "# plt.plot(x, y, color=\"black\")\n",
        "\n",
        "# # Additional Annotation\n",
        "# plt.annotate(\n",
        "#     'Performance stabilizing',\n",
        "#     xy=(4, y[4]),\n",
        "#     xytext=(4.5, y[4]-.05),\n",
        "#     arrowprops=dict(\n",
        "#         arrowstyle=\"-|>\",\n",
        "#         connectionstyle=\"arc3\",\n",
        "#         color=\"#00ACC1\")\n",
        "# )\n",
        "# plt.savefig(\"multiple_frozen_blocks.png\", dpi=300, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf785lzMjwiy"
      },
      "source": [
        "## Few-shot Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ybeQ3j6kOk4"
      },
      "outputs": [],
      "source": [
        "from setfit import sample_dataset\n",
        "\n",
        "# We simulate a few-shot setting by sampling 16 examples per class\n",
        "sampled_train_data = sample_dataset(tomatoes[\"train\"], num_samples=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y55TDrmSqHm"
      },
      "outputs": [],
      "source": [
        "from setfit import SetFitModel\n",
        "\n",
        "# Load a pre-trained SentenceTransformer model\n",
        "model = SetFitModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ10SpAXdNvC"
      },
      "outputs": [],
      "source": [
        "from setfit import TrainingArguments as SetFitTrainingArguments\n",
        "from setfit import Trainer as SetFitTrainer\n",
        "\n",
        "# Define training arguments\n",
        "args = SetFitTrainingArguments(\n",
        "    num_epochs=3, # The number of epochs to use for contrastive learning\n",
        "    num_iterations=20  # The number of text pairs to generate\n",
        ")\n",
        "args.eval_strategy = args.evaluation_strategy\n",
        "\n",
        "# Create trainer\n",
        "trainer = SetFitTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=sampled_train_data,\n",
        "    eval_dataset=test_data,\n",
        "    metric=\"f1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HDP5-9wRYZS"
      },
      "outputs": [],
      "source": [
        "# from setfit import SetFitTrainer\n",
        "\n",
        "# # Create trainer\n",
        "# trainer = SetFitTrainer(\n",
        "#     model=model,\n",
        "#     train_dataset=sampled_train_data,\n",
        "#     eval_dataset=test_data,\n",
        "#     metric=\"f1\",\n",
        "#     num_epochs=3, # The number of epochs to use for contrastive learning\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yaXeQJadWIS"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyRxiY32R3Jd"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on our test data\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aKIHJpCQdAm"
      },
      "outputs": [],
      "source": [
        "model.model_head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7NbUeSn-QSe"
      },
      "source": [
        "## MLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z35PD47AXXnv"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# Load model for Masked Language Modeling (MLM)\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgLardIvEFTG"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "   return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "# Tokenize data\n",
        "tokenized_train = train_data.map(preprocess_function, batched=True)\n",
        "tokenized_train = tokenized_train.remove_columns(\"label\")\n",
        "tokenized_test = test_data.map(preprocess_function, batched=True)\n",
        "tokenized_test = tokenized_test.remove_columns(\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7Yfg_2TECs_"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "# Masking Tokens\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=True,\n",
        "    mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqnA-ROy7ZRG"
      },
      "outputs": [],
      "source": [
        "# from transformers import DataCollatorForWholeWordMask\n",
        "\n",
        "# # Masking Whole Words\n",
        "# data_collator = DataCollatorForWholeWordMask(\n",
        "#     tokenizer=tokenizer,\n",
        "#     mlm=True,\n",
        "#     mlm_probability=0.15\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OduApRY03iOE"
      },
      "outputs": [],
      "source": [
        "# Training arguments for parameter tuning\n",
        "training_args = TrainingArguments(\n",
        "   \"model\",\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=10,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-cRB3QmEiXl"
      },
      "outputs": [],
      "source": [
        "# Save pre-trained tokenizer\n",
        "tokenizer.save_pretrained(\"mlm\")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save updated model\n",
        "model.save_pretrained(\"mlm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfxN1p8TOg2v"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load and create predictions\n",
        "mask_filler = pipeline(\"fill-mask\", model=\"bert-base-cased\")\n",
        "preds = mask_filler(\"What a horrible [MASK]!\")\n",
        "\n",
        "# Print results\n",
        "for pred in preds:\n",
        "    print(f\">>> {pred['sequence']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogk1hJ4zOlAU"
      },
      "outputs": [],
      "source": [
        "# Load and create predictions\n",
        "mask_filler = pipeline(\"fill-mask\", model=\"mlm\")\n",
        "preds = mask_filler(\"What a horrible [MASK]!\")\n",
        "\n",
        "# Print results\n",
        "for pred in preds:\n",
        "    print(f\">>> {pred['sequence']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sDqoG2NyeJO"
      },
      "source": [
        "## Named Entity Recognition\n",
        "\n",
        "Here are a number of interesting datasets you can also explore for NER:\n",
        "* tner/mit_movie_trivia\n",
        "* tner/mit_restaurant\n",
        "* wnut_17\n",
        "* conll2003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGDvXU-ZzJ3J"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOQlMioIGY33"
      },
      "outputs": [],
      "source": [
        "# The CoNLL-2003 dataset for NER\n",
        "dataset = load_dataset(\"conll2003\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOc5J7YgIPl8"
      },
      "outputs": [],
      "source": [
        "example = dataset[\"train\"][848]\n",
        "example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEPNSdADeAWD"
      },
      "outputs": [],
      "source": [
        "label2id = {\n",
        "    'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4,\n",
        "    'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8\n",
        "}\n",
        "id2label = {index: label for label, index in label2id.items()}\n",
        "label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtRCaz15AyjC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOrlt03kIt_f"
      },
      "outputs": [],
      "source": [
        "# Split individual tokens into sub-tokens\n",
        "token_ids = tokenizer(example[\"tokens\"], is_split_into_words=True)[\"input_ids\"]\n",
        "sub_tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
        "sub_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s5A3mzj6TXf"
      },
      "outputs": [],
      "source": [
        "def align_labels(examples):\n",
        "    token_ids = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = examples[\"ner_tags\"]\n",
        "\n",
        "    updated_labels = []\n",
        "    for index, label in enumerate(labels):\n",
        "\n",
        "        # Map tokens to their respective word\n",
        "        word_ids = token_ids.word_ids(batch_index=index)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "\n",
        "            # The start of a new word\n",
        "            if word_idx != previous_word_idx:\n",
        "\n",
        "                previous_word_idx = word_idx\n",
        "                updated_label = -100 if word_idx is None else label[word_idx]\n",
        "                label_ids.append(updated_label)\n",
        "\n",
        "            # Special token is -100\n",
        "            elif word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "\n",
        "            # If the label is B-XXX we change it to I-XXX\n",
        "            else:\n",
        "                updated_label = label[word_idx]\n",
        "                if updated_label % 2 == 1:\n",
        "                    updated_label += 1\n",
        "                label_ids.append(updated_label)\n",
        "\n",
        "        updated_labels.append(label_ids)\n",
        "\n",
        "    token_ids[\"labels\"] = updated_labels\n",
        "    return token_ids\n",
        "\n",
        "tokenized = dataset.map(align_labels, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIWOMzE-AhTu"
      },
      "outputs": [],
      "source": [
        "# Difference between original and updated labels\n",
        "print(f\"Original: {example['ner_tags']}\")\n",
        "print(f\"Updated: {tokenized['train'][848]['labels']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA9nE7E6g97p"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "# Load sequential evaluation\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # Create predictions\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=2)\n",
        "\n",
        "    true_predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Document-level iteration\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "\n",
        "      # token-level iteration\n",
        "      for token_prediction, token_label in zip(prediction, label):\n",
        "\n",
        "        # We ignore special tokens\n",
        "        if token_label != -100:\n",
        "          true_predictions.append([id2label[token_prediction]])\n",
        "          true_labels.append([id2label[token_label]])\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\"f1\": results[\"overall_f1\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0S4ZajdCaJl"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "# Token-classification Data Collator\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S76kRYZtBr5c"
      },
      "outputs": [],
      "source": [
        "# Training arguments for parameter tuning\n",
        "training_args = TrainingArguments(\n",
        "   \"model\",\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=1,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds5osPr9T0pq"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on our test data\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0PAXyzT-N45"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Save our fine-tuned model\n",
        "trainer.save_model(\"ner_model\")\n",
        "\n",
        "# Run inference on the fine-tuned model\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=\"ner_model\",\n",
        ")\n",
        "token_classifier(\"My name is Maarten.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAfBhqVwC61e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}