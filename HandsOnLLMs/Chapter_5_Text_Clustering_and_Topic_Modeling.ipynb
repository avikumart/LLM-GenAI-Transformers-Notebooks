{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avikumart/LLM-GenAI-Transformers-Notebooks/blob/main/HandsOnLLMs/Chapter_5_Text_Clustering_and_Topic_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIa-kJ-Frdm-"
      },
      "source": [
        "<h1>Chapter 5 - Text Clustering and Topic Modeling</h1>\n",
        "<i>Clustering documents using a wide variety of language models.</i>\n",
        "\n",
        "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\"><img src=\"https://img.shields.io/badge/Buy%20the%20Book!-grey?logo=amazon\"></a>\n",
        "<a href=\"https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/\"><img src=\"https://img.shields.io/badge/O'Reilly-white.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMzQiIGhlaWdodD0iMjciIHZpZXdCb3g9IjAgMCAzNCAyNyIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTMiIGN5PSIxNCIgcj0iMTEiIHN0cm9rZT0iI0Q0MDEwMSIgc3Ryb2tlLXdpZHRoPSI0Ii8+CjxjaXJjbGUgY3g9IjMwLjUiIGN5PSIzLjUiIHI9IjMuNSIgZmlsbD0iI0Q0MDEwMSIvPgo8L3N2Zz4K\"></a>\n",
        "<a href=\"https://github.com/HandsOnLLM/Hands-On-Large-Language-Models\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter05/Chapter%205%20-%20Text%20Clustering%20and%20Topic%20Modeling.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is for Chapter 5 of the [Hands-On Large Language Models](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961) book by [Jay Alammar](https://www.linkedin.com/in/jalammar) and [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/).\n",
        "\n",
        "---\n",
        "\n",
        "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\">\n",
        "<img src=\"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png\" width=\"350\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqYz5H4o52ZC"
      },
      "source": [
        "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
        "\n",
        "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ’¡ **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
        "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWz-HzMk52ZE"
      },
      "outputs": [],
      "source": [
        "!# %%capture\n",
        "!pip install bertopic datasets openai datamapplot -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "id": "6zD3US-L-8Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHIkQSBkV2Y3"
      },
      "source": [
        "# **ArXiv Articles: Computation and Language**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWSp_UCgWbr4"
      },
      "outputs": [],
      "source": [
        "# Load data from huggingface\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"maartengr/arxiv_nlp\", download_mode=\"force_redownload\")[\"train\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "tEmXjaQm_FuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles = dataset[\"Titles\"]\n",
        "abstracts = dataset[\"Abstracts\"]"
      ],
      "metadata": {
        "id": "uaKAqiUE_H1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcFT-b2QV3_r"
      },
      "source": [
        "# **A Common Pipeline for Text Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBpD9d2EV6HJ"
      },
      "source": [
        "## **1. Embedding Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woTpVEpCV5kH"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Create an embedding for each abstract\n",
        "embedding_model = SentenceTransformer('thenlper/gte-small')\n",
        "embeddings = embedding_model.encode(abstracts, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZwmECcNA519"
      },
      "outputs": [],
      "source": [
        "# Check the dimensions of the resulting embeddings\n",
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[:5]"
      ],
      "metadata": {
        "id": "AZcKFDrMB9pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_nsz_U7WEsw"
      },
      "source": [
        "## **2. Reducing the Dimensionality of Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXeo08d1WvOJ"
      },
      "outputs": [],
      "source": [
        "from umap import UMAP\n",
        "\n",
        "# We reduce the input embeddings from 384 dimenions to 5 dimenions\n",
        "umap_model = UMAP(\n",
        "    n_components=5, min_dist=0.0, metric='cosine', random_state=42\n",
        ")\n",
        "reduced_embeddings = umap_model.fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_embeddings.shape"
      ],
      "metadata": {
        "id": "4ZozHgqfCdLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqzr_8LFWGld"
      },
      "source": [
        "## **3. Cluster the Reduced Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwq6qDydgWSP"
      },
      "outputs": [],
      "source": [
        "from hdbscan import HDBSCAN\n",
        "\n",
        "# We fit the model and extract the clusters\n",
        "hdbscan_model = HDBSCAN(\n",
        "    min_cluster_size=50, metric='euclidean', cluster_selection_method='eom'\n",
        ").fit(reduced_embeddings)\n",
        "clusters = hdbscan_model.labels_\n",
        "\n",
        "# How many clusters did we generate?\n",
        "len(set(clusters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZh8mgujoZH3"
      },
      "source": [
        "## **Inspecting the Clusters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi6ACUR4pU0f"
      },
      "source": [
        "Manually inspect the first three documents in cluster 0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiPK4m0rpJl7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Print first three documents in cluster 0\n",
        "cluster = 1\n",
        "for index in np.where(clusters==cluster)[0][:3]:\n",
        "    print(abstracts[index][:350] + \"... \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9izgGjMX1Go"
      },
      "source": [
        "Next, we reduce our embeddings to 2-dimensions so that we can plot them and get a rough understanding of the generated clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzr6xbTEYcyl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reduce 384-dimensional embeddings to 2 dimensions for easier visualization\n",
        "reduced_embeddings = UMAP(\n",
        "    n_components=2, min_dist=0.0, metric='cosine', random_state=42\n",
        ").fit_transform(embeddings)\n",
        "\n",
        "# Create dataframe\n",
        "df = pd.DataFrame(reduced_embeddings, columns=[\"x\", \"y\"])\n",
        "df[\"title\"] = titles\n",
        "df[\"cluster\"] = [str(c) for c in clusters]\n",
        "\n",
        "# Select outliers and non-outliers (clusters)\n",
        "clusters_df = df.loc[df.cluster != \"-1\", :]\n",
        "outliers_df = df.loc[df.cluster == \"-1\", :]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "8IBGBTsRGSoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters_df[\"cluster\"].nunique()"
      ],
      "metadata": {
        "id": "kHmQd4AUNG7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3bUq3HHyQcw"
      },
      "source": [
        "### Static Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nptZUr0mLWSN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot outliers and non-outliers seperately\n",
        "plt.scatter(outliers_df.x, outliers_df.y, alpha=0.05, s=2, c=\"grey\")\n",
        "plt.scatter(\n",
        "    clusters_df.x, clusters_df.y, c=clusters_df.cluster.astype(int),\n",
        "    alpha=0.6, s=2, cmap='tab20b'\n",
        ")\n",
        "plt.axis('off')\n",
        "# plt.savefig(\"matplotlib.png\", dpi=300)  # Uncomment to save the graph as a .png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BgkDN8gWUUD"
      },
      "source": [
        "# From Text Clustering to Topic Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkYhkfUMMrpm"
      },
      "source": [
        "## **BERTopic: A Modular Topic Modeling Framework**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oySav_RqKvsS"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "# Train our model with our previously defined models\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=embedding_model,\n",
        "    umap_model=umap_model,\n",
        "    hdbscan_model=hdbscan_model,\n",
        "    verbose=True\n",
        ").fit(abstracts, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Popz6QTitaWB"
      },
      "source": [
        "Now, let's start exploring the topics that we got by running the code above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8vYjkscqUeX"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TNa-xEttfkf"
      },
      "source": [
        "Hundreds of topics were generated using the default model! To get the top 10 keywords per topic as well as their c-TF-IDF weights, we can use the `get_topic()` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPtrkto0wYyc"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8_tWTkowTLX"
      },
      "source": [
        "We can use the `find_topics()` function to search for specific topics based on a search term. Letâ€™s search for a topic about topic modeling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGzBPAt4pCfm"
      },
      "outputs": [],
      "source": [
        "topic_model.find_topics(\"topic modeling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nF29PoFwasH"
      },
      "source": [
        "It returns that topic 22 has a relatively high similarity (0.95) with our search term. If we then inspect the topic, we can see that it is indeed a topic about topic modeling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3rjQuPHwb2H"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwMgKD7OzFJs"
      },
      "source": [
        "That seems like a topic that is, in part, characterized by the classic LDA technique. Let's see if the BERTopic paper was also assigned to topic 22:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sp_WTxHazA-g"
      },
      "outputs": [],
      "source": [
        "topic_model.topics_[titles.index('BERTopic: Neural topic modeling with a class-based TF-IDF procedure')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5EZ3pvzzEpI"
      },
      "source": [
        "It is! We expected it might be because there are non-LDA specific words in the topic describtion such as \"clustering\" and \"topic\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jy6tpcRxOxN"
      },
      "source": [
        "### **Visualizations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxwMHwDA5H8-"
      },
      "source": [
        "**Visualize Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR6UXe1t5H8_"
      },
      "outputs": [],
      "source": [
        "# Visualize topics and documents\n",
        "fig = topic_model.visualize_documents(\n",
        "    titles,\n",
        "    reduced_embeddings=reduced_embeddings,\n",
        "    width=1200,\n",
        "    hide_annotations=True\n",
        ")\n",
        "\n",
        "# Update fonts of legend for easier visualization\n",
        "fig.update_layout(font=dict(size=16))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize barchart with ranked keywords\n",
        "topic_model.visualize_barchart()"
      ],
      "metadata": {
        "id": "6E33ZSB5R62Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize relationships between topics\n",
        "topic_model.visualize_heatmap(n_clusters=30)"
      ],
      "metadata": {
        "id": "x74xmJ3QR-Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2mvH4fSVzDr"
      },
      "outputs": [],
      "source": [
        "# Visualize the potential hierarchical structure of topics\n",
        "topic_model.visualize_hierarchy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-8h5SnZmLe5"
      },
      "source": [
        "## **Representation Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0vuZhqfmVEt"
      },
      "source": [
        "In these examples that follow, we will update our topic representations **after** having trained our model. This allows for quick iteration. If, however, you want to use a representation model at the start of training, you will need to run it as follows:\n",
        "\n",
        "```python\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "from bertopic import BERTopic\n",
        "\n",
        "# Create your representation model\n",
        "representation_model = KeyBERTInspired()\n",
        "\n",
        "# Use the representation model in BERTopic on top of the default pipeline\n",
        "topic_model = BERTopic(representation_model=representation_model)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY6hAIvOo9zT"
      },
      "source": [
        "To use the representation models, we are first going to duplicate our topic model such that easily show the differences between a model with and without representation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usLIeMFbqM7y"
      },
      "outputs": [],
      "source": [
        "# Save original representations\n",
        "from copy import deepcopy\n",
        "original_topics = deepcopy(topic_model.topic_representations_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dYLwbyEoeag"
      },
      "outputs": [],
      "source": [
        "def topic_differences(model, original_topics, nr_topics=5):\n",
        "    \"\"\"Show the differences in topic representations between two models \"\"\"\n",
        "    df = pd.DataFrame(columns=[\"Topic\", \"Original\", \"Updated\"])\n",
        "    for topic in range(nr_topics):\n",
        "\n",
        "        # Extract top 5 words per topic per model\n",
        "        og_words = \" | \".join(list(zip(*original_topics[topic]))[0][:5])\n",
        "        new_words = \" | \".join(list(zip(*model.get_topic(topic)))[0][:5])\n",
        "        df.loc[len(df)] = [topic, og_words, new_words]\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaDMxMIimNou"
      },
      "source": [
        "### KeyBERTInspired"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sp23Uzzr2KJ"
      },
      "outputs": [],
      "source": [
        "from bertopic.representation import KeyBERTInspired\n",
        "\n",
        "# Update our topic representations using KeyBERTInspired\n",
        "representation_model = KeyBERTInspired()\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# Show topic differences\n",
        "topic_differences(topic_model, original_topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7MV_-UiyCtS"
      },
      "source": [
        "### Maximal Marginal Relevance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGfm-c_-yEsp"
      },
      "outputs": [],
      "source": [
        "from bertopic.representation import MaximalMarginalRelevance\n",
        "\n",
        "# Update our topic representations to MaximalMarginalRelevance\n",
        "representation_model = MaximalMarginalRelevance(diversity=0.5)\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# Show topic differences\n",
        "topic_differences(topic_model, original_topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJez0aYvRmhw"
      },
      "source": [
        "## Text Generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZZRe0dkSWko"
      },
      "source": [
        "### Flan-T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yisDTfcIrbq"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from bertopic.representation import TextGeneration\n",
        "\n",
        "prompt = \"\"\"I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "\n",
        "The topic is described by the following keywords: '[KEYWORDS]'.\n",
        "\n",
        "Based on the documents and keywords, what is this topic about?\"\"\"\n",
        "\n",
        "# Update our topic representations using Flan-T5\n",
        "generator = pipeline('text2text-generation', model='google/flan-t5-small')\n",
        "representation_model = TextGeneration(\n",
        "    generator, prompt=prompt, doc_length=50, tokenizer=\"whitespace\"\n",
        ")\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# Show topic differences\n",
        "topic_differences(topic_model, original_topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zah9jGGsgkP_"
      },
      "source": [
        "### OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXhqvQ2agkQF"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from bertopic.representation import OpenAI\n",
        "\n",
        "prompt = \"\"\"\n",
        "I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "\n",
        "The topic is described by the following keywords: [KEYWORDS]\n",
        "\n",
        "Based on the information above, extract a short topic label in the following format:\n",
        "topic: <short topic label>\n",
        "\"\"\"\n",
        "\n",
        "# Update our topic representations using GPT-3.5\n",
        "client = openai.OpenAI(api_key=\"YOUR_KEY_HERE\")\n",
        "representation_model = OpenAI(\n",
        "    client, model=\"gpt-3.5-turbo\", exponential_backoff=True, chat=True, prompt=prompt\n",
        ")\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# Show topic differences\n",
        "topic_differences(topic_model, original_topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36c3UUvXZ8L-"
      },
      "outputs": [],
      "source": [
        "# Visualize topics and documents\n",
        "fig = topic_model.visualize_document_datamap(\n",
        "    titles,\n",
        "    topics=list(range(20)),\n",
        "    reduced_embeddings=reduced_embeddings,\n",
        "    width=1200,\n",
        "    label_font_size=11,\n",
        "    label_wrap_width=20,\n",
        "    use_medoids=True,\n",
        ")\n",
        "plt.savefig(\"datamapplot.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj9Z47wkxTzl"
      },
      "source": [
        "\n",
        "## **BONUS**: Word Cloud\n",
        "\n",
        "Make sure to pip install `wordcloud` first in order to follow this bonus:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdq9LzkxzxzT"
      },
      "source": [
        "First, we need to make sure that each topic is described by a bit more words than just 10 as that would make for a much more interesting wordcloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qT2IKjyfxkkV"
      },
      "outputs": [],
      "source": [
        "topic_model.update_topics(abstracts, top_n_words=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3NIkt0Hz4AJ"
      },
      "source": [
        "Then, we can run the following code to generate the wordcloud for our topic modeling topic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFSNG30jxWGo"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_wordcloud(model, topic):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    text = {word: value for word, value in model.get_topic(topic)}\n",
        "    wc = WordCloud(background_color=\"white\", max_words=1000, width=1600, height=800)\n",
        "    wc.generate_from_frequencies(text)\n",
        "    plt.imshow(wc, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Show wordcloud\n",
        "create_wordcloud(topic_model, topic=17)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}